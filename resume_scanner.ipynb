{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEuokTJxO_AG",
    "outputId": "67a7b881-b2e0-46f8-fb09-041a14389673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Using legacy 'setup.py install' for docx2txt, since package 'wheel' is not installed.\n",
      "Installing collected packages: docx2txt\n",
      "  Running setup.py install for docx2txt: started\n",
      "  Running setup.py install for docx2txt: finished with status 'done'\n",
      "Successfully installed docx2txt-0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "C0HYo1x1P3eN"
   },
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "job_description=docx2txt.process('job_description.docx')\n",
    "resume=docx2txt.process('RESUME1.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Xbqd6JQQOIx",
    "outputId": "442ea4a3-4fd9-4278-fda7-59883fe1d0ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESUME OBJECTIVE\n",
      "\n",
      "Data Scientist with 4+ years of experience executing data-driven solutions to increase efficiency, accuracy, and utility of internal data processing. Experienced at creating data regression models, using predictive data modeling, and analyzing data mining algorithms to deliver insights and implement action-oriented solutions to complex business problems. Looking to use my Bachelor of Computer Science and Master of Science in Statistics to manage statistical machine learning and data-related solutions at your organization.\n",
      "\n",
      "PROFESSIONAL EXPERIENCE\n",
      "\n",
      "Microsoft – Tucson, AZ\n",
      "\n",
      "Data Scientist                                                                                                September 2021 – Present\n",
      "\n",
      "Conducted a data regression analysis of the relationship between company stock prices and industry trends, achieving a 15% more accurate prediction of performance than previous years\n",
      "\n",
      "Utilized web scraping techniques to extract and organize competitor data\n",
      "\n",
      "Increased accessibility and usability of customer data by redesigning data visualization techniques to include statistical graphs and information graphics\n",
      "\n",
      "Updated company data warehousing techniques such as data recall and segmentation, resulting in a 20% increase in usability for non-technical staff members\n",
      "\n",
      "Updated data streamlining processes, resulting in a 25% redundancy reduction\n",
      "\n",
      "Hewlett-Packard – San Francisco, CA\n",
      "\n",
      "Data Scientist                                                                                               January 2017 – March 2021\n",
      "\n",
      "Improved data mining processes, resulting in a 20% decrease in time needed to infer insights from customer data used to develop marketing strategies\n",
      "\n",
      "Used predictive analytics such as machine learning and data mining techniques to forecast company sales of new products with a 95% accuracy rate\n",
      "\n",
      "Increased data security by updating companywide encryption, steganography, IP security, and secure wireless transmission practices\n",
      "\n",
      "Developed ETS for data sources used for reporting by sales, inventory, and marketing departments\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "UNIVERSITY OF CALIFORNIA, BERKELEY – Berkeley, CA\n",
      "\n",
      "Master of Science in Statistics, June 2017\n",
      "\n",
      "GPA 3.8/4\n",
      "\n",
      "THE UNIVERSITY OF ARIZONA – Tucson, AZ\n",
      "\n",
      "Bachelor of Computer Science, June 2015\n",
      "\n",
      "GPA 3.9/4\n",
      "\n",
      "ADDITIONAL SKILLS\n",
      "\n",
      "Proficient in PHP, Ruby on Rails, Java, C++, and Python\n",
      "\n",
      "Experienced at managing relational and non-relational database software such as MySQL, SQLite3, Mongo DB, and JSON\n",
      "\n",
      "Technical leadership and training data management activities such as collection, cleansing, standardization, and mining\n"
     ]
    }
   ],
   "source": [
    "print(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IF9afZpVQh7b"
   },
   "outputs": [],
   "source": [
    "content=[job_description, resume]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.2-cp310-cp310-win_amd64.whl (7.4 MB)\n",
      "     ---------------------------------------- 7.4/7.4 MB 4.9 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     -------------------------------------- 307.0/307.0 kB 6.3 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.9.0-cp310-cp310-win_amd64.whl (38.6 MB)\n",
      "     ---------------------------------------- 38.6/38.6 MB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.23.1)\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "  Running setup.py install for sklearn: started\n",
      "  Running setup.py install for sklearn: finished with status 'done'\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.1.2 scipy-1.9.0 sklearn-0.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4HE3t8kBQsab"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "matrix= cv.fit_transform(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "cKFTnO2AQ8JU"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix=cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3viHSciERgas",
    "outputId": "58ab4eb4-51ab-4ed8-b916-fa7576c5828f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.76891761]\n",
      " [0.76891761 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NXDR_4tRmLS",
    "outputId": "41748e75-060b-4d86-c371-f6dbb8405721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume matched with 76.89%\n"
     ]
    }
   ],
   "source": [
    "print('Resume matched with ' +str(round(similarity_matrix[1][0]*100,2))+ '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQmA8uqu7M-A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "resume_scanner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
